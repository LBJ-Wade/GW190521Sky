{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab widget\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.cosmology as cosmo\n",
    "from astropy.cosmology import Planck15\n",
    "import astropy.units as u\n",
    "import h5py\n",
    "from kde_contour import kdeplot_2d_clevels\n",
    "import ligo.skymap.kde\n",
    "import pandas as pd\n",
    "from scipy.integrate import cumtrapz\n",
    "import scipy.stats as ss\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm as tqdm_book\n",
    "import warnings\n",
    "\n",
    "sns.set_context('notebook')\n",
    "sns.set_palette('husl', n_colors=6)\n",
    "sns.set_style('ticks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posterior sample file dowloaded from https://dcc.ligo.org/LIGO-P2000158/public.  There are multiple approximants in the file, but the \"preferred\" results come from a \"NR surrogate\" `NRSur7dq4`.  Execute the `curl` command below to re-download the posterior sample file and compare its MD5.  I, Farr, find \n",
    "```shell\n",
    "% openssl md5 GW190521_posterior_samples.h5\n",
    "MD5(GW190521_posterior_samples.h5)= 8af9bce0b55b5ebed7853dbfaa69a2d5\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -O https://dcc.ligo.org/public/0168/P2000158/004/GW190521_posterior_samples.h5\n",
    "!openssl md5 GW190521_posterior_samples.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IMRPhenomPv3HM', 'NRSur7dq4', 'SEOBNRv4PHM', 'history', 'version']\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('GW190521_posterior_samples.h5', 'r') as f:\n",
    "    print(list(f.keys()))\n",
    "    samples = array(f['NRSur7dq4/posterior_samples'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(227735503557159763068367766824777508503)\n",
    "c = rng.choice(len(samples), replace=False, size=16384)\n",
    "sky_samples = pd.DataFrame({\n",
    "    'x': samples['luminosity_distance'][c]*cos(samples['ra'][c])*cos(samples['dec'][c]),\n",
    "    'y': samples['luminosity_distance'][c]*sin(samples['ra'][c])*cos(samples['dec'][c]),\n",
    "    'z': samples['luminosity_distance'][c]*sin(samples['dec'][c])\n",
    "})\n",
    "sky_samples_plot = pd.DataFrame({\n",
    "    r'$x$ ($\\mathrm{Mpc}$)': samples['luminosity_distance'][c]*cos(samples['ra'][c])*cos(samples['dec'][c]),\n",
    "    r'$y$ ($\\mathrm{Mpc}$)': samples['luminosity_distance'][c]*sin(samples['ra'][c])*cos(samples['dec'][c]),\n",
    "    r'$z$ ($\\mathrm{Mpc}$)': samples['luminosity_distance'][c]*sin(samples['dec'][c])\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Graham, et al. (2020)](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.124.251102) reports the AGN at $\\mathrm{RA} = 192.42625^\\circ$, $\\mathrm{DEC} = 34.82472^\\circ$, and $z = 0.438$.  Converting to $xyz$ we have "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra = 192.42625*pi/180.0\n",
    "dec = 34.82472*pi/180\n",
    "zcounter = 0.438\n",
    "dcounter = Planck15.luminosity_distance(zcounter).to(u.Mpc).value\n",
    "xcounter = dcounter*cos(ra)*cos(dec)\n",
    "ycounter = dcounter*sin(ra)*cos(dec)\n",
    "zcounter = dcounter*sin(dec)\n",
    "\n",
    "pt_counter = array([xcounter, ycounter, zcounter])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a pretty typical skymap: there are two blobs on the sky.  It would be better to do some clustering or use the routines in https://lscsoft.docs.ligo.org/ligo.skymap/#plotting-and-visualization-ligo-skymap-plot, but we're being quick and dirty here.  The KDE that is estimated from the 3D positions will be over-dispersed because its bandwidth will be trying to account for the two blobs on either side of the origin; so take these results with a grain of salt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec9804a578c469984e8b228f2b473f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore') # Don't bitch about unused 'label' keyword.\n",
    "    g = sns.PairGrid(sky_samples, diag_sharey=False)\n",
    "    g.map_diag(sns.kdeplot)\n",
    "    g.map_lower(kdeplot_2d_clevels)\n",
    "    g.map_upper(sns.scatterplot)\n",
    "\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            if i == j:\n",
    "                g.axes[i,j].axvline(pt_counter[i], color='k')\n",
    "            else:\n",
    "                g.axes[i,j].axhline(pt_counter[i], color='k')\n",
    "                g.axes[i,j].axvline(pt_counter[j], color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, let's look at it in 3D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf9c8adc8834329861fbb50743fb071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '$z$ ($\\\\mathrm{Mpc}$)')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(sky_samples['x'], sky_samples['y'], sky_samples['z'], marker='.', s=5, alpha=0.05)\n",
    "ax.scatter(xcounter, ycounter, zcounter, marker='*', color='k', s=20)\n",
    "ax.set_xlabel(r'$x$ ($\\mathrm{Mpc}$)')\n",
    "ax.set_ylabel(r'$y$ ($\\mathrm{Mpc}$)')\n",
    "ax.set_zlabel(r'$z$ ($\\mathrm{Mpc}$)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a quick sense of the fraction of the volume posterior that would have to be searched before landing on the AGN, we rank the posterior samples according to an estimate of their 3D posterior density, and determine what fraction lie at lower rank than the AGN location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGN lies at the 0.82 percentile of the posterior\n"
     ]
    }
   ],
   "source": [
    "pts = row_stack((sky_samples['x'], sky_samples['y'], sky_samples['z']))\n",
    "kde = ss.gaussian_kde(pts)\n",
    "p_pts = kde(pts)\n",
    "p_counterpart = kde(pt_counter)\n",
    "\n",
    "print('AGN lies at the {:.2f} percentile of the posterior'.format(count_nonzero(p_pts > p_counterpart) / float(len(p_pts))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the marginal distance posterior along the LOS to the AGN.  Again, remember that the KDE is over-dispersed; a proper analysis would be more careful about clustering before computing KDEs.  Given that, however, we can just evaluate the full posterior along the line toward the AGN and re-normalize to obtain the conditional posterior for distance at the AGN location.\n",
    "\n",
    "Note that this is the conditional posterior density in 3D luminosity-volume---and since our prior is flat in this space, this is proportional to the GW likelihood for distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_counter = sqrt(dot(pt_counter, pt_counter))\n",
    "ds = linspace(0, 4*r_counter, 1024)\n",
    "xhat = pt_counter / sqrt(dot(pt_counter, pt_counter))\n",
    "pdist = kde(row_stack(ds[newaxis,:]*xhat[:,newaxis]))\n",
    "pdist /= trapz(pdist, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb9b54d763544802ae1e2f242d0d87bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$p\\\\left( d_\\\\mathrm{GW} \\\\mid d_L, \\\\mathrm{RA}=\\\\alpha, \\\\mathrm{DEC}=\\\\delta \\\\right)$')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure()\n",
    "plot(ds, pdist)\n",
    "axvline(r_counter, color='k')\n",
    "xlabel(r'$d_L$ ($\\mathrm{Mpc}$)')\n",
    "ylabel(r'$p\\left( d_\\mathrm{GW} \\mid d_L, \\mathrm{RA}=\\alpha, \\mathrm{DEC}=\\delta \\right)$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes these things work better in the principal axes of the skymap.  Here's what that looks like.  We rotate the point cloud so that the covariance matrix is diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = column_stack((sky_samples['x'], sky_samples['y'], sky_samples['z']))\n",
    "S = cov(pts, rowvar=False)\n",
    "evals, evecs = np.linalg.eigh(S)\n",
    "rot_pts = np.dot(evecs.T, pts.T).T\n",
    "rot_counter = np.dot(evecs.T, pt_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_sky = pd.DataFrame({\n",
    "    r'$\\tilde{x}$ ($\\mathrm{Mpc}$)': rot_pts[:,0],\n",
    "    r'$\\tilde{y}$ ($\\mathrm{Mpc}$)': rot_pts[:,1],\n",
    "    r'$\\tilde{z}$ ($\\mathrm{Mpc}$)': rot_pts[:,2]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63604a7f67b4d14b1c6cd6cfc8a663a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore') # Don't bitch about unused 'label' keyword.\n",
    "    g = sns.PairGrid(rot_sky, diag_sharey=False)\n",
    "    g.map_diag(sns.kdeplot)\n",
    "    g.map_lower(kdeplot_2d_clevels)\n",
    "    g.map_upper(sns.scatterplot)\n",
    "\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            if i == j:\n",
    "                g.axes[i,j].axvline(rot_counter[i], color='k')\n",
    "            else:\n",
    "                g.axes[i,j].axhline(rot_counter[i], color='k')\n",
    "                g.axes[i,j].axvline(rot_counter[j], color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the clusters separate well across the origin in $\\tilde{z}$ so let's just implement that by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sel = rot_pts[:,2]>0\n",
    "neg_sel = rot_pts[:,2]<0\n",
    "N_pos = count_nonzero(pos_sel)\n",
    "N_neg = count_nonzero(neg_sel)\n",
    "kde_pos = ss.gaussian_kde(rot_pts[pos_sel,:].T)\n",
    "kde_neg = ss.gaussian_kde(rot_pts[neg_sel,:].T)\n",
    "\n",
    "def cdens(pts):\n",
    "    return (N_pos*kde_pos(pts) + N_neg*kde_neg(pts))/(N_pos+N_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_pts = cdens(rot_pts.T)\n",
    "p_counter = cdens(rot_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counterpart found at the 0.70 credible level of the posterior\n"
     ]
    }
   ],
   "source": [
    "print('Counterpart found at the {:.2f} credible level of the posterior'.format(count_nonzero(p_pts > p_counter) / float(len(p_pts))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the contour levels, but with the split KDE; you can see why there is a better credible level for the counterpart because the split KDE brings out the \"bump\" in the $z > 0$ cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ab8df790d945159a4a6cd94fa3723e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def kdeplot_2d_clevels_split(xs, ys, levels=11, **kwargs):\n",
    "    try:\n",
    "        len(levels)\n",
    "        f = 1 - np.array(levels)\n",
    "    except TypeError:\n",
    "        f = linspace(0, 1, levels)[1:-1]\n",
    "    k_pos = ss.gaussian_kde(row_stack((xs[pos_sel], ys[pos_sel])))\n",
    "    k_neg = ss.gaussian_kde(row_stack((xs[neg_sel], ys[neg_sel])))\n",
    "    k = lambda pts: (N_pos*k_pos(pts) + N_neg*k_neg(pts))/(N_pos+N_neg)\n",
    "    size = max(10*(len(f)+2), 500)\n",
    "    c = np.random.choice(len(xs), size=size)\n",
    "    p = k(row_stack((xs[c], ys[c])))\n",
    "    i = argsort(p)\n",
    "    l = array([p[i[int(round(ff*len(i)))]] for ff in f])\n",
    "\n",
    "    Dx = np.percentile(xs, 99) - np.percentile(xs, 1)\n",
    "    Dy = np.percentile(ys, 99) - np.percentile(ys, 1)\n",
    "\n",
    "    x = linspace(np.percentile(xs, 1)-0.1*Dx, np.percentile(xs, 99)+0.1*Dx, 128)\n",
    "    y = linspace(np.percentile(ys, 1)-0.1*Dy, np.percentile(ys, 99)+0.1*Dy, 128)\n",
    "\n",
    "    XS, YS = meshgrid(x, y, indexing='ij')\n",
    "    ZS = k(row_stack((XS.flatten(), YS.flatten()))).reshape(XS.shape)\n",
    "\n",
    "    if 'cmap' not in kwargs:\n",
    "        line, = plot([], [])\n",
    "        kwargs['cmap'] = sns.dark_palette(line.get_color(), as_cmap=True)\n",
    "\n",
    "    ax = kwargs.pop('ax', gca())\n",
    "\n",
    "    ax.contour(XS, YS, ZS, levels=l, **kwargs)\n",
    "\n",
    "def kdeplot_split(xs, *args, **kwargs):\n",
    "    xmin = np.min(xs)\n",
    "    xmax = np.max(xs)\n",
    "    Dx = xmax - xmin\n",
    "    \n",
    "    xplot = linspace(xmin-0.1*Dx, xmax+0.1*Dx, 1024)\n",
    "    k_pos = ss.gaussian_kde(xs[pos_sel])\n",
    "    k_neg = ss.gaussian_kde(xs[neg_sel])\n",
    "    \n",
    "    plot(xplot, (N_pos*k_pos(xplot) + N_neg*k_neg(xplot))/(N_pos+N_neg), *args, **kwargs)\n",
    "    \n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore') # Don't bitch about unused 'label' keyword.\n",
    "    g = sns.PairGrid(rot_sky, diag_sharey=False)\n",
    "    g.map_diag(kdeplot_split)\n",
    "    g.map_lower(kdeplot_2d_clevels_split)\n",
    "    g.map_upper(sns.scatterplot)\n",
    "\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            if i == j:\n",
    "                g.axes[i,j].axvline(rot_counter[i], color='k')\n",
    "            else:\n",
    "                g.axes[i,j].axhline(rot_counter[i], color='k')\n",
    "                g.axes[i,j].axvline(rot_counter[j], color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about a 3D version that uses the estimated log-posterior to color the points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "143ab64aa96f4843973b7c17d14215ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '$z$ ($\\\\mathrm{Mpc}$)')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(sky_samples['x'], sky_samples['y'], sky_samples['z'], marker='.', s=5, alpha=0.02, cmap='viridis', c=p_pts, norm=mpl.colors.LogNorm())\n",
    "ax.scatter(xcounter, ycounter, zcounter, marker='*', color='k', s=20)\n",
    "ax.set_xlabel(r'$x$ ($\\mathrm{Mpc}$)')\n",
    "ax.set_ylabel(r'$y$ ($\\mathrm{Mpc}$)')\n",
    "ax.set_zlabel(r'$z$ ($\\mathrm{Mpc}$)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can make the same conditional distance posterior plot as above using the new clustered KDE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "double check: d = 2492.434 Mpc, rot_d = 2492.434 Mpc\n"
     ]
    }
   ],
   "source": [
    "rot_d = np.sqrt(np.dot(rot_counter, rot_counter)) # Better be the same as D---that's what rotations do....\n",
    "print('double check: d = {:.3f} Mpc, rot_d = {:.3f} Mpc'.format(dcounter, rot_d)) # Whew\n",
    "rot_counter_hat = rot_counter / rot_d\n",
    "\n",
    "ds = linspace(0, 5*rot_d, 1024)\n",
    "ps = rot_counter_hat[newaxis,:]*ds[:,newaxis]\n",
    "pps = cdens(ps.T)\n",
    "pps /= trapz(pps, ds) # Normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we evaluate the clustered "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb37fee46464a44ae87a184a5bf044d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$p\\\\left( d_\\\\mathrm{GW} \\\\mid d_L, \\\\mathrm{RA}=\\\\alpha, \\\\mathrm{DEC}=\\\\delta \\\\right)$')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure()\n",
    "plot(ds, pps)\n",
    "axvline(rot_d, color='k')\n",
    "xlabel(r'$d_L$ ($\\mathrm{Mpc}$)')\n",
    "ylabel(r'$p\\left( d_\\mathrm{GW} \\mid d_L, \\mathrm{RA}=\\alpha, \\mathrm{DEC}=\\delta \\right)$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to avoid the clustering / KDEing issue entirely, here we just cut the posterior samples down to those w/i a 3-degree cone around the AGN location.  (I chose 3 degrees via the very scientific procedure of that being the first integer cone angular size that had more than 1k points in it.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05b2c53abab94bc38dc7d39fce07dda9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-f716185a0204>:5: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ps = (k(ds) + k(-ds))/(ds*ds) # Reflect about d = 0 boundary\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$p\\\\left( d_\\\\mathrm{GW} \\\\mid d_L, \\\\mathrm{RA}=\\\\alpha, \\\\mathrm{DEC}=\\\\delta \\\\right)$')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure()\n",
    "r = 3 # deg\n",
    "sel = np.sqrt(np.square((ra - samples['ra'])*cos(dec)) + np.square((dec - samples['dec']))) < r*pi/180.0\n",
    "k = ss.gaussian_kde(samples['luminosity_distance'][sel])\n",
    "ps = (k(ds) + k(-ds))/(ds*ds) # Reflect about d = 0 boundary\n",
    "ps[0] = 0.0 # Singularity at d = 0\n",
    "pps = ps / trapz(ps, ds)\n",
    "plot(ds, pps)\n",
    "xlabel(r'$d_L$ ($\\mathrm{Mpc}$)')\n",
    "ylabel(r'$p\\left( d_\\mathrm{GW} \\mid d_L, \\mathrm{RA}=\\alpha, \\mathrm{DEC}=\\delta \\right)$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see where the counterpart falls in the conditional distance posterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With default d_L^2 prior, counterpart found at 0.03 CL\n"
     ]
    }
   ],
   "source": [
    "ds_cond = samples['luminosity_distance'][sel]\n",
    "print('With default d_L^2 prior, counterpart found at {:.2f} CL'.format(count_nonzero(ds_cond < dcounter)/float(len(ds_cond))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But a more reasonable prior would be uniform in comoving volume, not uniform in $d_L^3$.  Re-weighting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1356/1356 [00:07<00:00, 183.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With uniform in comoving frame prior, counterpart found at 0.08 CL\n"
     ]
    }
   ],
   "source": [
    "zs_cond = array([cosmo.z_at_value(Planck15.luminosity_distance, d*u.Mpc) for d in tqdm(ds_cond)])\n",
    "z_wt = (4*pi*Planck15.differential_comoving_volume(zs_cond)/(1+zs_cond)/Planck15.luminosity_distance(zs_cond)**2).value\n",
    "zcounter = cosmo.z_at_value(Planck15.luminosity_distance, dcounter*u.Mpc)\n",
    "\n",
    "print('With uniform in comoving frame prior, counterpart found at {:.2f} CL'.format(np.sum(z_wt[zs_cond < zcounter])/np.sum(z_wt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fun exercise is to use the measured redshift of the AGN ($z = 0.438$) to turn our distance measurement into a measurement of $H_0$ (assuming other cosmological parameters are fixed).  Let's compute a marginal likelihood for $H_0$, at least for $35 \\, \\mathrm{km} \\, \\mathrm{s}^{-1} \\, \\mathrm{Mpc}^{-1} \\leq H_0 \\leq 140 \\, \\mathrm{km} \\, \\mathrm{s}^{-1} \\, \\mathrm{Mpc}^{-1}$.  That means we need to work out what the implied prior is on $H_0$ given the LVC's $d_L^2$ prior on distance (applies to both the conditional and un-conditional distances).  A nice trick for measuring $H_0$ in this very simplified model is to note that it is inversely proportional to luminosity distance, so \n",
    "$$\n",
    "H_0\\left( d_L \\mid z_\\mathrm{AGN} \\right) = \\frac{d_{L,\\mathrm{AGN}}\\left( z_\\mathrm{AGN} \\mid H_{0,\\mathrm{Planck}} \\right)}{d_L} H_{0, \\mathrm{Planck}},\n",
    "$$\n",
    "which works as long as we hold the remainder of cosmology fixed (since $H_0$ is then just a scale factor on the inverse luminosity distance).  \n",
    "\n",
    "What we have plotted above is evaluating the 3D KDE for the location in luminosity distance space along the ray toward the counterpart; since the LIGO/Virgo/Kagra prior is uniform in this 3D space, this is proportional to the likelihood function evaluated along the ray.  Thus, we do not need any Jacobian transformation to remove the prior; we just need to evaluate our likelihood in terms of $H_0$, which we do below. \n",
    "\n",
    "This has been a point of confusion, and the next-to-last, incorrect reasoning that appeared previously in this notebook is below:\n",
    "\n",
    "**Here is an incorrect piece of reasoning**\n",
    "\n",
    "We want to convert our posterior on $d_L$ into a likelihood, so we need to divide by the prior (LIGO uses $d_L^2 \\propto H_0^{-2}$).  Once we have a likelihood function, there is no further change needed to write it in terms of $H_0$ instead of $d_L$ (note: I messed this up the first time I made this plot; I multiplied by $H_0^4$ as if converting posteriors, but forgot that there needs to be an additional factor of $\\partial d / \\partial H_0 \\propto H_0^{-2}$, leaving a net $H_0^{-2}$ as we discuss here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-390196a84025>:1: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  H0_of_d = rot_d / ds * Planck15.H0.to(u.km/u.s/u.Mpc).value\n"
     ]
    }
   ],
   "source": [
    "H0_of_d = rot_d / ds * Planck15.H0.to(u.km/u.s/u.Mpc).value\n",
    "sel = (35 < H0_of_d) & (H0_of_d < 140)\n",
    "H0_of_d = H0_of_d[sel][::-1]\n",
    "p_H0 = pps.copy()[sel][::-1]\n",
    "p_H0 /= trapz(p_H0, H0_of_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e4272e510d5413b8a75b43260a15dc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planck15 H0 found at p = 0.43 in likelihood\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '$H_0 = 72^{+25}_{-24} \\\\, \\\\mathrm{km} \\\\, \\\\mathrm{s}^{-1} \\\\, \\\\mathrm{Mpc}^{-1}$')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure()\n",
    "plot(H0_of_d, p_H0)\n",
    "axvline(Planck15.H0.to(u.km/u.s/u.Mpc).value, color='k')\n",
    "xlabel(r'$H_0$ ($\\mathrm{km} \\, \\mathrm{s}^{-1} \\, \\mathrm{Mpc}^{-1}$)')\n",
    "ylabel(r'$p\\left( d_\\mathrm{GW}, z_\\mathrm{AGN} | H_0 \\right)$')\n",
    "\n",
    "c_H0 = cumtrapz(p_H0, H0_of_d, initial=0)\n",
    "print('Planck15 H0 found at p = {:.2f} in likelihood'.format(interp(Planck15.H0.to(u.km/u.s/u.Mpc).value, H0_of_d, c_H0)))\n",
    "m = interp(0.5, c_H0, H0_of_d)\n",
    "l = interp(0.16, c_H0, H0_of_d)\n",
    "h = interp(0.84, c_H0, H0_of_d)\n",
    "title(r'$H_0 = {:.0f}^{{+{:.0f}}}_{{-{:.0f}}} \\, \\mathrm{{km}} \\, \\mathrm{{s}}^{{-1}} \\, \\mathrm{{Mpc}}^{{-1}}$'.format(m, h-m, m-l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bayes factor (i.e. likelihood of association) is given by the posterior density at the proposed counterpart divided by the prior density.  The LIGO prior is uniform in (luminosity distance)^3, so in our rotated xyz coordinate system it is uniform, and given by $1/V$ where $V$ is the volume of the prior region.  If we take this to be a sphere that encloses all our posterior samples, but only just, then we obtain the \"minimal\" Bayes factor for the association, computed below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes factor for the association is 34.9\n"
     ]
    }
   ],
   "source": [
    "prior_density = 1/(4/3*pi*np.max(samples['luminosity_distance'])**3)\n",
    "bf = p_counterpart / prior_density\n",
    "print('Bayes factor for the association is {:.1f}'.format(bf[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to consider selection effects.  This is going to be a complete hack, but given the accuracy of our measurement is hopefully OK.  We need to introduce a weighting factor, $\\beta\\left( H_0 \\right)$ (see, e.g., [Abbott, et al. (2017)](https://arxiv.org/pdf/1710.05835.pdf), [Fishbach, et al. (2018)](https://arxiv.org/pdf/1807.05667.pdf), [Farr & Gair (2018)](https://github.com/farr/H0StatisticalLikelihood)), that accounts for the fraction of the population of GW+EM events that is observable.  We make the following simplifying assumptions:\n",
    "\n",
    "* Any AGN merger flaring event that is detectable in GW is either also detectable as a EM flare, or would be missing an EM detection *at random* (e.g. if the EM followup us only able to observe some subset of the sky that is independent of the event properties).  This lets us only consider the GW selection function.\n",
    "* We approximate the GW selection function as a fixed luminosity distance cut.  In reality the observable volume for any class of system has a non-uniform shape on the sky, and further varies as a function of the intrinsic properties of the event; so this is a *very rough* approximation.\n",
    "\n",
    "But under these approximations, then the `beta` factor is just the fraction of the (properly normalized!) population that is detectable.  Below we evaluate this factor under two reasonable assumptions: \n",
    "\n",
    "1. That the merger rate is constant in the comoving frame to $z = 10$.\n",
    "1. That the merger rate traces the [Madau & Dickinson (2014)](https://arxiv.org/abs/1403.0007) star formation rate in the comoving frame with $1 < z < 10$:\n",
    "  $$\n",
    "  \\frac{\\mathrm{d} N}{\\mathrm{d} V \\mathrm{d} t} \\propto \\frac{\\left( 1 + z \\right)^{2.7}}{1 + \\left( \\frac{1 + z}{1 + 1.9} \\right)^{5.6}}\n",
    "  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:03<00:00, 39.88it/s]\n"
     ]
    }
   ],
   "source": [
    "zs = expm1(linspace(log(1), log(1+10), 1024))\n",
    "H0s = logspace(log10(35), log10(140), 128)\n",
    "dL_horiz = 15.0\n",
    "betas_unif = []\n",
    "for H in tqdm(H0s):\n",
    "    c = cosmo.FlatLambdaCDM(H*u.km/u.s/u.Mpc, Planck15.Om0)\n",
    "    pz = Planck15.differential_comoving_volume(zs).to(u.Gpc**3/u.sr).value/(1+zs)\n",
    "    pz /= trapz(pz, zs)\n",
    "    cz = cumtrapz(pz, zs, initial=0)\n",
    "    betas_unif.append(interp(cosmo.z_at_value(c.luminosity_distance, dL_horiz*u.Gpc), zs, cz))\n",
    "betas_unif = array(betas_unif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:03<00:00, 34.37it/s]\n"
     ]
    }
   ],
   "source": [
    "zs = expm1(linspace(log(1), log(1+20), 1024))\n",
    "H0s = logspace(log10(35), log10(140), 128)\n",
    "dL_horiz = 15.0\n",
    "betas_MD = []\n",
    "for H in tqdm(H0s):\n",
    "    c = cosmo.FlatLambdaCDM(H*u.km/u.s/u.Mpc, Planck15.Om0)\n",
    "    pz = (1+zs)**2.7/(1 + ((1+zs)/(1+1.9))**5.6)*Planck15.differential_comoving_volume(zs).to(u.Gpc**3/u.sr).value/(1+zs)\n",
    "    pz /= trapz(pz, zs)\n",
    "    cz = cumtrapz(pz, zs, initial=0)\n",
    "    betas_MD.append(interp(cosmo.z_at_value(c.luminosity_distance, dL_horiz*u.Gpc), zs, cz))\n",
    "betas_MD = array(betas_MD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d088edaf91dd420d83e95497ff5ed9cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure()\n",
    "with sns.color_palette('husl', n_colors=2):\n",
    "    plot(H0s, betas_unif, label='Uniform Comoving')\n",
    "    plot(H0s, betas_MD, label='Madau-Dickinson')\n",
    "    legend(loc='best')\n",
    "    xlabel(r'$H_0$ ($\\mathrm{km}\\,\\mathrm{s}^{-1}\\,\\mathrm{Mpc}^{-1}$)')\n",
    "    ylabel(r'$\\beta\\left( H_0 \\right)$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correcting for selection, we find:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_H0_unif = p_H0 / interp(H0_of_d, H0s, betas_unif)\n",
    "p_H0_MD = p_H0 / interp(H0_of_d, H0s, betas_MD)\n",
    "\n",
    "p_H0_unif /= trapz(p_H0_unif, H0_of_d)\n",
    "p_H0_MD /= trapz(p_H0_MD, H0_of_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f9567325714d8580e72362f7724a54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planck15 H0 found at p = 0.64 in likelihood (M-D selection)\n"
     ]
    }
   ],
   "source": [
    "figure()\n",
    "with sns.color_palette('husl', n_colors=3):\n",
    "    plot(H0_of_d, p_H0, label='No Selection')\n",
    "    plot(H0_of_d, p_H0_unif, label='Uniform Comoving')\n",
    "    plot(H0_of_d, p_H0_MD, label='Madau-Dickinson')\n",
    "    axvline(Planck15.H0.to(u.km/u.s/u.Mpc).value, color='k')\n",
    "    xlabel(r'$H_0$ ($\\mathrm{km} \\, \\mathrm{s}^{-1} \\, \\mathrm{Mpc}^{-1}$)')\n",
    "    ylabel(r'$p\\left( d_\\mathrm{GW}, z_\\mathrm{AGN} | H_0 \\right)$')\n",
    "\n",
    "    c_H0 = cumtrapz(p_H0_MD, H0_of_d, initial=0)\n",
    "    print('Planck15 H0 found at p = {:.2f} in likelihood (M-D selection)'.format(interp(Planck15.H0.to(u.km/u.s/u.Mpc).value, H0_of_d, c_H0)))\n",
    "    m = interp(0.5, c_H0, H0_of_d)\n",
    "    l = interp(0.16, c_H0, H0_of_d)\n",
    "    h = interp(0.84, c_H0, H0_of_d)\n",
    "    title(r'$H_0 = {:.0f}^{{+{:.0f}}}_{{-{:.0f}}} \\, \\mathrm{{km}} \\, \\mathrm{{s}}^{{-1}} \\, \\mathrm{{Mpc}}^{{-1}}$ (M-D population)'.format(m, h-m, m-l))\n",
    "    legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
